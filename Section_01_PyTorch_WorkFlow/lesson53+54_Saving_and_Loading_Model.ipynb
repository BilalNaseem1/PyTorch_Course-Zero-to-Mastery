{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOQLktnfLGr0h4FeaMwlDWc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import torch\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from torch import nn"],"metadata":{"id":"LybANCMpsZ0n","executionInfo":{"status":"ok","timestamp":1700466416602,"user_tz":-300,"elapsed":388,"user":{"displayName":"Bilal Naseem","userId":"05735064512837959343"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# CREATING DATA AND TRAIN TEST SPLIT\n","\n","# Create *known* parameters\n","weight = 0.7\n","bias = 0.3\n","\n","# Create data\n","start = 0\n","end = 1\n","step = 0.02\n","X = torch.arange(start, end, step).unsqueeze(dim=1)\n","y = weight * X + bias\n","\n","# Create train/test split\n","train_split = int(0.8 * len(X)) # 80% of data used for training set, 20% for testing\n","X_train, y_train = X[:train_split], y[:train_split]\n","X_test, y_test = X[train_split:], y[train_split:]\n","\n","len(X_train), len(y_train), len(X_test), len(y_test)\n","\n","\n","# Creating the Model\n","\n","# Creating a linear regression model class\n","class LinearRegressionModel(nn.Module):\n","  # Creating constructor\n","  def __init__(self):\n","    super().__init__()\n","    self.weights = nn.Parameter(torch.randn(1, # <- start with random weights (this will get adjusted as the model learns)\n","                                            dtype = torch.float), # <- PyTorch loves float32 by default\n","                                            requires_grad = True) # by default is also true\n","    self.bias = nn.Parameter(torch.randn(1,\n","                                         dtype = torch.float), # <- PyTorch loves float32 by default\n","                                          requires_grad = True)\n","\n","    # Forward method to define the computation in the model\n","  def forward(self, x: torch.Tensor) -> torch.Tensor: # <- \"x\" is the input data\n","    return self.weights * x + self.bias # this is the linear regression formula\n","\n","\n","torch.manual_seed(42) # we'll get the same initial values when using seed\n","model_0 = LinearRegressionModel() # calling the class\n","\n","\n","# Defining the loss function and Optimizer\n","\n","loss_fn = nn.L1Loss()\n","\n","optimizer = torch.optim.SGD(params = model_0.parameters(),\n","                            lr = 0.01)\n","\n","torch.manual_seed(42)\n","\n","epochs = 100 # hyperparameter\n","\n","# 1. Loop through the data\n","for epoch in range(epochs):\n","  # setting the model in training mode\n","  model_0.train()  # ----->>>>>>> train mode in PyTorch sets all parameters that require gradients to require gradients\n","\n","  # 2. Forward pass\n","  y_pred = model_0(X_train)\n","\n","  # 3. Calculate the loss\n","  loss = loss_fn(y_pred, y_train) # predictions, labels\n","  print(f\"Loss: {loss}\")\n","\n","  # 4. Optimizer 0 grad\n","  optimizer.zero_grad()\n","\n","  # 5. Perform backpropagation on the loss wrt parameters of the model\n","  loss.backward()\n","\n","  # 6. Step the optimizer (perform gradient descent)\n","  optimizer.step()                  # it accumilates the value that it's supposed to change through the loop\n","\n","\n","  # Testing\n","  model_0.eval()  # Evaluation mode: Turns off different settings in the model not needed for evaluation/testing purposes (dropout/batch normalization)\n","\n","  with torch.inference_mode(): # turns off gradient tracking + other things - to make te code faster\n","    # 1. Forward pass\n","    test_pred = model_0(X_test)\n","\n","    # 2. Calculate loss\n","    test_loss = loss_fn(test_pred, y_test)\n","\n","  if epoch %10 ==0: # not printing what's happening in every epoch\n","    print(f\"Epoch: {epoch} | Test: {loss} | {test_loss}\")\n","    print(model_0.state_dict())\n"],"metadata":{"id":"4pt7zD-EsZwW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Lesson 53 - Saving a model"],"metadata":{"id":"hiv5Ehnjq7z3"}},{"cell_type":"markdown","source":["There are 3 ways to save a model in PyTorch:\n","1. `torch.save():` allows to save a PyTorch object in Python's pickle format\n","2. `torch.load():` allows to load a saved pytorch object\n","3. `torch.nn.load_state_dict():` allows to load a model's saved state dictionary"],"metadata":{"id":"CGcNsrQHrAAF"}},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VgJkFlklqvar","executionInfo":{"status":"ok","timestamp":1700466436006,"user_tz":-300,"elapsed":17,"user":{"displayName":"Bilal Naseem","userId":"05735064512837959343"}},"outputId":"70dbad13-e10a-4b10-c9f2-3becb20ea322"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["OrderedDict([('weights', tensor([0.5784])), ('bias', tensor([0.3513]))])"]},"metadata":{},"execution_count":4}],"source":["model_0.state_dict()"]},{"cell_type":"markdown","source":["- `state_dict():` stores important parameters in a simple python dictionary\n","- Dictionary that holds the state of the model\n","- but later on we may be working with millions of parameters, so looking at state_dict may not be easy"],"metadata":{"id":"_IOGS617st6C"}},{"cell_type":"markdown","source":["## Saving PyTorch Model"],"metadata":{"id":"5phHur-btQ-z"}},{"cell_type":"code","source":["from pathlib import Path\n","\n","# 1. Creating a model directory\n","MODEL_PATH = Path(\"models\")\n","MODEL_PATH.mkdir(parents=True, exist_ok=True)\n","\n","# 2. Create model save path\n","MODEL_NAME = \"01_pytorch_workflow_model_0.pth\" # we save using .pt or .pth extension\n","MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n","\n","MODEL_SAVE_PATH"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hQnb6nTHsqPa","executionInfo":{"status":"ok","timestamp":1700466991582,"user_tz":-300,"elapsed":22,"user":{"displayName":"Bilal Naseem","userId":"05735064512837959343"}},"outputId":"9eeceb78-992b-4369-8f35-9a1e4f831355"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PosixPath('models/01_pytorch_workflow_model_0.pth')"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["torch.save(obj= model_0.state_dict(),\n","           f=MODEL_SAVE_PATH)"],"metadata":{"id":"s48aD_1fux3B","executionInfo":{"status":"ok","timestamp":1700467132264,"user_tz":-300,"elapsed":21,"user":{"displayName":"Bilal Naseem","userId":"05735064512837959343"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["!ls -l models"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3BO2HKJ7vUI3","executionInfo":{"status":"ok","timestamp":1700467172250,"user_tz":-300,"elapsed":12,"user":{"displayName":"Bilal Naseem","userId":"05735064512837959343"}},"outputId":"4f5a5834-bb3a-4337-df25-57607bcf9f84"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["total 4\n","-rw-r--r-- 1 root root 1680 Nov 20 07:58 01_pytorch_workflow_model_0.pth\n"]}]},{"cell_type":"markdown","source":["- Here we saved the model's state_dict() (recommended)\n","- We can also save the entire model"],"metadata":{"id":"rM5jBhD8vo17"}},{"cell_type":"markdown","source":["## Loading the Model"],"metadata":{"id":"npAHfEfwwFTO"}},{"cell_type":"markdown","source":["- Since we saved the model's state_dict rather than the entire model, we'll create a new instance of our model class and load the save state_dict() into that.\n","- To load in the state_dict(), we have to instantiate a new instance of our model class"],"metadata":{"id":"vzctVtuQwTD7"}},{"cell_type":"code","source":["loaded_model_0 = LinearRegressionModel()"],"metadata":{"id":"2lNMflMavd1o","executionInfo":{"status":"ok","timestamp":1700467544835,"user_tz":-300,"elapsed":12,"user":{"displayName":"Bilal Naseem","userId":"05735064512837959343"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["loaded_model_0.state_dict()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MRmvkwOMxH6_","executionInfo":{"status":"ok","timestamp":1700467614322,"user_tz":-300,"elapsed":16,"user":{"displayName":"Bilal Naseem","userId":"05735064512837959343"}},"outputId":"2b8d5d64-1887-4579-d487-f08b81af7bbf"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["OrderedDict([('weights', tensor([0.3367])), ('bias', tensor([0.1288]))])"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["- It is iniallized with random parameters"],"metadata":{"id":"Xlifanl2xNEl"}},{"cell_type":"code","source":["# loading the saved state_dict of model_0\n","# this will update the new instance with updated parameters\n","\n","loaded_model_0.load_state_dict(torch.load(f=MODEL_SAVE_PATH))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LPe-9CtDw453","executionInfo":{"status":"ok","timestamp":1700468826400,"user_tz":-300,"elapsed":530,"user":{"displayName":"Bilal Naseem","userId":"05735064512837959343"}},"outputId":"e289cfd4-7fc8-41d2-ad26-f8a879144718"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["loaded_model_0.state_dict()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jTqQn6UA1xuq","executionInfo":{"status":"ok","timestamp":1700468843425,"user_tz":-300,"elapsed":4,"user":{"displayName":"Bilal Naseem","userId":"05735064512837959343"}},"outputId":"decb9e71-a326-4e52-e1db-f02dbaf8cde5"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["OrderedDict([('weights', tensor([0.5784])), ('bias', tensor([0.3513]))])"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["- Our parameters are now updated"],"metadata":{"id":"VISgko-J14IP"}},{"cell_type":"markdown","source":["## Making predictions"],"metadata":{"id":"giuJzQUS1-W6"}},{"cell_type":"code","source":["# for making predictions we are in evaluation mode\n","loaded_model_0.eval()\n","\n","with torch.inference_mode():\n","  loaded_model_preds = loaded_model_0(X_test)\n","\n","loaded_model_preds"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u0GWLzHk101h","executionInfo":{"status":"ok","timestamp":1700469323199,"user_tz":-300,"elapsed":7,"user":{"displayName":"Bilal Naseem","userId":"05735064512837959343"}},"outputId":"66e2a150-3e28-4830-fee1-3d7086f1ad4f"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.8141],\n","        [0.8256],\n","        [0.8372],\n","        [0.8488],\n","        [0.8603],\n","        [0.8719],\n","        [0.8835],\n","        [0.8950],\n","        [0.9066],\n","        [0.9182]])"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":[],"metadata":{"id":"KXEaeszl3rE7"},"execution_count":null,"outputs":[]}]}